digraph {
	graph [size="59.25,59.25"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3145803910896 [label="
 (1, 3)" fillcolor=darkolivegreen1]
	3145325713712 [label=AddmmBackward0]
	3145325721632 -> 3145325713712
	3145325999696 [label="fc.bias
 (3)" fillcolor=lightblue]
	3145325999696 -> 3145325721632
	3145325721632 [label=AccumulateGrad]
	3145325721584 -> 3145325713712
	3145325721584 [label=ViewBackward0]
	3145325713664 -> 3145325721584
	3145325713664 [label=MeanBackward1]
	3145325721776 -> 3145325713664
	3145325721776 [label=ReluBackward0]
	3145325721872 -> 3145325721776
	3145325721872 [label=AddBackward0]
	3145325721968 -> 3145325721872
	3145325721968 [label=CudnnBatchNormBackward0]
	3145325722112 -> 3145325721968
	3145325722112 [label=ConvolutionBackward0]
	3145325722304 -> 3145325722112
	3145325722304 [label=ReluBackward0]
	3145325722448 -> 3145325722304
	3145325722448 [label=CudnnBatchNormBackward0]
	3145325722544 -> 3145325722448
	3145325722544 [label=ConvolutionBackward0]
	3145325721920 -> 3145325722544
	3145325721920 [label=ReluBackward0]
	3145325722880 -> 3145325721920
	3145325722880 [label=AddBackward0]
	3145325722784 -> 3145325722880
	3145325722784 [label=CudnnBatchNormBackward0]
	3145325723216 -> 3145325722784
	3145325723216 [label=ConvolutionBackward0]
	3145325723072 -> 3145325723216
	3145325723072 [label=ReluBackward0]
	3145325723408 -> 3145325723072
	3145325723408 [label=CudnnBatchNormBackward0]
	3145325723360 -> 3145325723408
	3145325723360 [label=ConvolutionBackward0]
	3145325723600 -> 3145325723360
	3145325723600 [label=ReluBackward0]
	3145803874464 -> 3145325723600
	3145803874464 [label=AddBackward0]
	3145803874560 -> 3145803874464
	3145803874560 [label=CudnnBatchNormBackward0]
	3145803874752 -> 3145803874560
	3145803874752 [label=ConvolutionBackward0]
	3145803874896 -> 3145803874752
	3145803874896 [label=ReluBackward0]
	3145803875040 -> 3145803874896
	3145803875040 [label=CudnnBatchNormBackward0]
	3145803875136 -> 3145803875040
	3145803875136 [label=ConvolutionBackward0]
	3145803874512 -> 3145803875136
	3145803874512 [label=ReluBackward0]
	3145803875424 -> 3145803874512
	3145803875424 [label=AddBackward0]
	3145803875520 -> 3145803875424
	3145803875520 [label=CudnnBatchNormBackward0]
	3145803875664 -> 3145803875520
	3145803875664 [label=ConvolutionBackward0]
	3145803875856 -> 3145803875664
	3145803875856 [label=ReluBackward0]
	3145803876000 -> 3145803875856
	3145803876000 [label=CudnnBatchNormBackward0]
	3145803876096 -> 3145803876000
	3145803876096 [label=ConvolutionBackward0]
	3145803876288 -> 3145803876096
	3145803876288 [label=ReluBackward0]
	3145803876432 -> 3145803876288
	3145803876432 [label=AddBackward0]
	3145803876528 -> 3145803876432
	3145803876528 [label=CudnnBatchNormBackward0]
	3145803876672 -> 3145803876528
	3145803876672 [label=ConvolutionBackward0]
	3145803876864 -> 3145803876672
	3145803876864 [label=ReluBackward0]
	3145803877008 -> 3145803876864
	3145803877008 [label=CudnnBatchNormBackward0]
	3145803877104 -> 3145803877008
	3145803877104 [label=ConvolutionBackward0]
	3145803876480 -> 3145803877104
	3145803876480 [label=ReluBackward0]
	3145803877392 -> 3145803876480
	3145803877392 [label=AddBackward0]
	3145803877488 -> 3145803877392
	3145803877488 [label=CudnnBatchNormBackward0]
	3145803877632 -> 3145803877488
	3145803877632 [label=ConvolutionBackward0]
	3145803877824 -> 3145803877632
	3145803877824 [label=ReluBackward0]
	3145803877968 -> 3145803877824
	3145803877968 [label=CudnnBatchNormBackward0]
	3145803878064 -> 3145803877968
	3145803878064 [label=ConvolutionBackward0]
	3145803878256 -> 3145803878064
	3145803878256 [label=ReluBackward0]
	3145803878400 -> 3145803878256
	3145803878400 [label=AddBackward0]
	3145803878496 -> 3145803878400
	3145803878496 [label=CudnnBatchNormBackward0]
	3145803878640 -> 3145803878496
	3145803878640 [label=ConvolutionBackward0]
	3145803878832 -> 3145803878640
	3145803878832 [label=ReluBackward0]
	3145803878976 -> 3145803878832
	3145803878976 [label=CudnnBatchNormBackward0]
	3145803879072 -> 3145803878976
	3145803879072 [label=ConvolutionBackward0]
	3145803878448 -> 3145803879072
	3145803878448 [label=ReluBackward0]
	3145803879360 -> 3145803878448
	3145803879360 [label=AddBackward0]
	3145803879456 -> 3145803879360
	3145803879456 [label=CudnnBatchNormBackward0]
	3145803879600 -> 3145803879456
	3145803879600 [label=ConvolutionBackward0]
	3145803879792 -> 3145803879600
	3145803879792 [label=ReluBackward0]
	3145803879936 -> 3145803879792
	3145803879936 [label=CudnnBatchNormBackward0]
	3145803880032 -> 3145803879936
	3145803880032 [label=ConvolutionBackward0]
	3145803879408 -> 3145803880032
	3145803879408 [label=ReluBackward0]
	3145803880320 -> 3145803879408
	3145803880320 [label=CudnnBatchNormBackward0]
	3145803880416 -> 3145803880320
	3145803880416 [label=ConvolutionBackward0]
	3145803880608 -> 3145803880416
	3145325619600 [label="conv1.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	3145325619600 -> 3145803880608
	3145803880608 [label=AccumulateGrad]
	3145803880368 -> 3145803880320
	3145325988272 [label="conv1.1.weight
 (64)" fillcolor=lightblue]
	3145325988272 -> 3145803880368
	3145803880368 [label=AccumulateGrad]
	3145803880128 -> 3145803880320
	3145325988368 [label="conv1.1.bias
 (64)" fillcolor=lightblue]
	3145325988368 -> 3145803880128
	3145803880128 [label=AccumulateGrad]
	3145803880224 -> 3145803880032
	3145325988752 [label="conv2_x.0.residual_function.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3145325988752 -> 3145803880224
	3145803880224 [label=AccumulateGrad]
	3145803879984 -> 3145803879936
	3145325988848 [label="conv2_x.0.residual_function.1.weight
 (64)" fillcolor=lightblue]
	3145325988848 -> 3145803879984
	3145803879984 [label=AccumulateGrad]
	3145803879840 -> 3145803879936
	3145325988944 [label="conv2_x.0.residual_function.1.bias
 (64)" fillcolor=lightblue]
	3145325988944 -> 3145803879840
	3145803879840 [label=AccumulateGrad]
	3145803879744 -> 3145803879600
	3145325989328 [label="conv2_x.0.residual_function.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3145325989328 -> 3145803879744
	3145803879744 [label=AccumulateGrad]
	3145803879552 -> 3145803879456
	3145325989424 [label="conv2_x.0.residual_function.4.weight
 (64)" fillcolor=lightblue]
	3145325989424 -> 3145803879552
	3145803879552 [label=AccumulateGrad]
	3145803879504 -> 3145803879456
	3145325989520 [label="conv2_x.0.residual_function.4.bias
 (64)" fillcolor=lightblue]
	3145325989520 -> 3145803879504
	3145803879504 [label=AccumulateGrad]
	3145803879408 -> 3145803879360
	3145803879264 -> 3145803879072
	3145325989904 [label="conv2_x.1.residual_function.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3145325989904 -> 3145803879264
	3145803879264 [label=AccumulateGrad]
	3145803879024 -> 3145803878976
	3145325990000 [label="conv2_x.1.residual_function.1.weight
 (64)" fillcolor=lightblue]
	3145325990000 -> 3145803879024
	3145803879024 [label=AccumulateGrad]
	3145803878880 -> 3145803878976
	3145325990096 [label="conv2_x.1.residual_function.1.bias
 (64)" fillcolor=lightblue]
	3145325990096 -> 3145803878880
	3145803878880 [label=AccumulateGrad]
	3145803878784 -> 3145803878640
	3145325990480 [label="conv2_x.1.residual_function.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	3145325990480 -> 3145803878784
	3145803878784 [label=AccumulateGrad]
	3145803878592 -> 3145803878496
	3145325990576 [label="conv2_x.1.residual_function.4.weight
 (64)" fillcolor=lightblue]
	3145325990576 -> 3145803878592
	3145803878592 [label=AccumulateGrad]
	3145803878544 -> 3145803878496
	3145325990672 [label="conv2_x.1.residual_function.4.bias
 (64)" fillcolor=lightblue]
	3145325990672 -> 3145803878544
	3145803878544 [label=AccumulateGrad]
	3145803878448 -> 3145803878400
	3145803878208 -> 3145803878064
	3145325991056 [label="conv3_x.0.residual_function.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	3145325991056 -> 3145803878208
	3145803878208 [label=AccumulateGrad]
	3145803878016 -> 3145803877968
	3145325991152 [label="conv3_x.0.residual_function.1.weight
 (128)" fillcolor=lightblue]
	3145325991152 -> 3145803878016
	3145803878016 [label=AccumulateGrad]
	3145803877872 -> 3145803877968
	3145325991248 [label="conv3_x.0.residual_function.1.bias
 (128)" fillcolor=lightblue]
	3145325991248 -> 3145803877872
	3145803877872 [label=AccumulateGrad]
	3145803877776 -> 3145803877632
	3145325991632 [label="conv3_x.0.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3145325991632 -> 3145803877776
	3145803877776 [label=AccumulateGrad]
	3145803877584 -> 3145803877488
	3145325991728 [label="conv3_x.0.residual_function.4.weight
 (128)" fillcolor=lightblue]
	3145325991728 -> 3145803877584
	3145803877584 [label=AccumulateGrad]
	3145803877536 -> 3145803877488
	3145325991824 [label="conv3_x.0.residual_function.4.bias
 (128)" fillcolor=lightblue]
	3145325991824 -> 3145803877536
	3145803877536 [label=AccumulateGrad]
	3145803877440 -> 3145803877392
	3145803877440 [label=CudnnBatchNormBackward0]
	3145803878160 -> 3145803877440
	3145803878160 [label=ConvolutionBackward0]
	3145803878256 -> 3145803878160
	3145803878304 -> 3145803878160
	3145325992208 [label="conv3_x.0.shortcut.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	3145325992208 -> 3145803878304
	3145803878304 [label=AccumulateGrad]
	3145803877728 -> 3145803877440
	3145325992304 [label="conv3_x.0.shortcut.1.weight
 (128)" fillcolor=lightblue]
	3145325992304 -> 3145803877728
	3145803877728 [label=AccumulateGrad]
	3145803877680 -> 3145803877440
	3145325992400 [label="conv3_x.0.shortcut.1.bias
 (128)" fillcolor=lightblue]
	3145325992400 -> 3145803877680
	3145803877680 [label=AccumulateGrad]
	3145803877296 -> 3145803877104
	3145325992784 [label="conv3_x.1.residual_function.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3145325992784 -> 3145803877296
	3145803877296 [label=AccumulateGrad]
	3145803877056 -> 3145803877008
	3145325992880 [label="conv3_x.1.residual_function.1.weight
 (128)" fillcolor=lightblue]
	3145325992880 -> 3145803877056
	3145803877056 [label=AccumulateGrad]
	3145803876912 -> 3145803877008
	3145325992976 [label="conv3_x.1.residual_function.1.bias
 (128)" fillcolor=lightblue]
	3145325992976 -> 3145803876912
	3145803876912 [label=AccumulateGrad]
	3145803876816 -> 3145803876672
	3145325993360 [label="conv3_x.1.residual_function.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	3145325993360 -> 3145803876816
	3145803876816 [label=AccumulateGrad]
	3145803876624 -> 3145803876528
	3145325993456 [label="conv3_x.1.residual_function.4.weight
 (128)" fillcolor=lightblue]
	3145325993456 -> 3145803876624
	3145803876624 [label=AccumulateGrad]
	3145803876576 -> 3145803876528
	3145325993552 [label="conv3_x.1.residual_function.4.bias
 (128)" fillcolor=lightblue]
	3145325993552 -> 3145803876576
	3145803876576 [label=AccumulateGrad]
	3145803876480 -> 3145803876432
	3145803876240 -> 3145803876096
	3145325993936 [label="conv4_x.0.residual_function.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	3145325993936 -> 3145803876240
	3145803876240 [label=AccumulateGrad]
	3145803876048 -> 3145803876000
	3145325994032 [label="conv4_x.0.residual_function.1.weight
 (256)" fillcolor=lightblue]
	3145325994032 -> 3145803876048
	3145803876048 [label=AccumulateGrad]
	3145803875904 -> 3145803876000
	3145325994128 [label="conv4_x.0.residual_function.1.bias
 (256)" fillcolor=lightblue]
	3145325994128 -> 3145803875904
	3145803875904 [label=AccumulateGrad]
	3145803875808 -> 3145803875664
	3145325994512 [label="conv4_x.0.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3145325994512 -> 3145803875808
	3145803875808 [label=AccumulateGrad]
	3145803875616 -> 3145803875520
	3145325994608 [label="conv4_x.0.residual_function.4.weight
 (256)" fillcolor=lightblue]
	3145325994608 -> 3145803875616
	3145803875616 [label=AccumulateGrad]
	3145803875568 -> 3145803875520
	3145325994704 [label="conv4_x.0.residual_function.4.bias
 (256)" fillcolor=lightblue]
	3145325994704 -> 3145803875568
	3145803875568 [label=AccumulateGrad]
	3145803875472 -> 3145803875424
	3145803875472 [label=CudnnBatchNormBackward0]
	3145803876192 -> 3145803875472
	3145803876192 [label=ConvolutionBackward0]
	3145803876288 -> 3145803876192
	3145803876336 -> 3145803876192
	3145325995088 [label="conv4_x.0.shortcut.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	3145325995088 -> 3145803876336
	3145803876336 [label=AccumulateGrad]
	3145803875760 -> 3145803875472
	3145325995184 [label="conv4_x.0.shortcut.1.weight
 (256)" fillcolor=lightblue]
	3145325995184 -> 3145803875760
	3145803875760 [label=AccumulateGrad]
	3145803875712 -> 3145803875472
	3145325995280 [label="conv4_x.0.shortcut.1.bias
 (256)" fillcolor=lightblue]
	3145325995280 -> 3145803875712
	3145803875712 [label=AccumulateGrad]
	3145803875328 -> 3145803875136
	3145325995664 [label="conv4_x.1.residual_function.0.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3145325995664 -> 3145803875328
	3145803875328 [label=AccumulateGrad]
	3145803875088 -> 3145803875040
	3145325995760 [label="conv4_x.1.residual_function.1.weight
 (256)" fillcolor=lightblue]
	3145325995760 -> 3145803875088
	3145803875088 [label=AccumulateGrad]
	3145803874944 -> 3145803875040
	3145325995856 [label="conv4_x.1.residual_function.1.bias
 (256)" fillcolor=lightblue]
	3145325995856 -> 3145803874944
	3145803874944 [label=AccumulateGrad]
	3145803874848 -> 3145803874752
	3145325996240 [label="conv4_x.1.residual_function.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	3145325996240 -> 3145803874848
	3145803874848 [label=AccumulateGrad]
	3145803874608 -> 3145803874560
	3145325996336 [label="conv4_x.1.residual_function.4.weight
 (256)" fillcolor=lightblue]
	3145325996336 -> 3145803874608
	3145803874608 [label=AccumulateGrad]
	3145803874656 -> 3145803874560
	3145325996432 [label="conv4_x.1.residual_function.4.bias
 (256)" fillcolor=lightblue]
	3145325996432 -> 3145803874656
	3145803874656 [label=AccumulateGrad]
	3145803874512 -> 3145803874464
	3145325723552 -> 3145325723360
	3145325996816 [label="conv5_x.0.residual_function.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	3145325996816 -> 3145325723552
	3145325723552 [label=AccumulateGrad]
	3145325723456 -> 3145325723408
	3145325996912 [label="conv5_x.0.residual_function.1.weight
 (512)" fillcolor=lightblue]
	3145325996912 -> 3145325723456
	3145325723456 [label=AccumulateGrad]
	3145325722976 -> 3145325723408
	3145325997008 [label="conv5_x.0.residual_function.1.bias
 (512)" fillcolor=lightblue]
	3145325997008 -> 3145325722976
	3145325722976 [label=AccumulateGrad]
	3145325723024 -> 3145325723216
	3145325997392 [label="conv5_x.0.residual_function.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3145325997392 -> 3145325723024
	3145325723024 [label=AccumulateGrad]
	3145325722688 -> 3145325722784
	3145325997488 [label="conv5_x.0.residual_function.4.weight
 (512)" fillcolor=lightblue]
	3145325997488 -> 3145325722688
	3145325722688 [label=AccumulateGrad]
	3145325722736 -> 3145325722784
	3145325997584 [label="conv5_x.0.residual_function.4.bias
 (512)" fillcolor=lightblue]
	3145325997584 -> 3145325722736
	3145325722736 [label=AccumulateGrad]
	3145325722832 -> 3145325722880
	3145325722832 [label=CudnnBatchNormBackward0]
	3145325723264 -> 3145325722832
	3145325723264 [label=ConvolutionBackward0]
	3145325723600 -> 3145325723264
	3145325723504 -> 3145325723264
	3145325997968 [label="conv5_x.0.shortcut.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	3145325997968 -> 3145325723504
	3145325723504 [label=AccumulateGrad]
	3145325723168 -> 3145325722832
	3145325998064 [label="conv5_x.0.shortcut.1.weight
 (512)" fillcolor=lightblue]
	3145325998064 -> 3145325723168
	3145325723168 [label=AccumulateGrad]
	3145325723120 -> 3145325722832
	3145325998160 [label="conv5_x.0.shortcut.1.bias
 (512)" fillcolor=lightblue]
	3145325998160 -> 3145325723120
	3145325723120 [label=AccumulateGrad]
	3145325713904 -> 3145325722544
	3145325998544 [label="conv5_x.1.residual_function.0.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3145325998544 -> 3145325713904
	3145325713904 [label=AccumulateGrad]
	3145325722496 -> 3145325722448
	3145325998640 [label="conv5_x.1.residual_function.1.weight
 (512)" fillcolor=lightblue]
	3145325998640 -> 3145325722496
	3145325722496 [label=AccumulateGrad]
	3145325722352 -> 3145325722448
	3145325998736 [label="conv5_x.1.residual_function.1.bias
 (512)" fillcolor=lightblue]
	3145325998736 -> 3145325722352
	3145325722352 [label=AccumulateGrad]
	3145325722256 -> 3145325722112
	3145325999120 [label="conv5_x.1.residual_function.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	3145325999120 -> 3145325722256
	3145325722256 [label=AccumulateGrad]
	3145325722064 -> 3145325721968
	3145325999216 [label="conv5_x.1.residual_function.4.weight
 (512)" fillcolor=lightblue]
	3145325999216 -> 3145325722064
	3145325722064 [label=AccumulateGrad]
	3145325722016 -> 3145325721968
	3145325999312 [label="conv5_x.1.residual_function.4.bias
 (512)" fillcolor=lightblue]
	3145325999312 -> 3145325722016
	3145325722016 [label=AccumulateGrad]
	3145325721920 -> 3145325721872
	3145325721536 -> 3145325713712
	3145325721536 [label=TBackward0]
	3145325721824 -> 3145325721536
	3145325999600 [label="fc.weight
 (3, 512)" fillcolor=lightblue]
	3145325999600 -> 3145325721824
	3145325721824 [label=AccumulateGrad]
	3145325713712 -> 3145803910896
}
